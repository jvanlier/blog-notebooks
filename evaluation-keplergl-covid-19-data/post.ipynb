{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "layout: post\n",
    "title:  \"An evaluation of Kepler.gl for Covid-19-style geographic timeseries\"\n",
    "date:   2020-05-01 14:00:00 +0200\n",
    "categories: blog\n",
    "permalink: \n",
    "math: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm a big fan of visualizing how things change over time on maps. Previously, this had me plotting ugly maps with matplotlib-based tooling, writing jpegs to a filesystem and combining them to a video or gif with `ffmpeg`. Not an entirely pleasant experience. When I first realised that [Kepler.gl](https://kepler.gl/), the mapping tool built by Uber, not only looks great, but has built-in time series support as well, it got me pretty excited!\n",
    "\n",
    "I will be evaluating Kepler.gl in this post when using it with geographic time series data. In particular, with the kind of daily data, aggregated per region, that we see a lot during the Covid-19 epidemic. \n",
    "\n",
    "The dataset that I will be using was made in a simulation of Covid-19 infections in neighbourhoods around Schiphol in The Netherlands, made earlier in [this post](https://jvlanalytics.nl/covid-19-simulation).\n",
    "\n",
    "**Update 2020-05-02:** I decided to also create a version of [the circle map (Map 1) with real worldwide data](/assets/blog/2020-05-01-evaluation-keplergl-covid-19-data/covid-19-map.html), rather than demoing only simulated data. I used [this data source](https://github.com/CSSEGISandData/COVID-19/). As I've explained below, try not to change the size of the time range, as that will just result in circles being drawn on top of each other. Refresh to reset it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from IPython.display import HTML\n",
    "from keplergl import KeplerGl\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "DATA_PATH = Path(\"../covid-19-simulation/data\")\n",
    "SIM_NAME = \"SimulationResult(n_days=250,tr_day=50,sd_day=40)\"\n",
    "SIM_RES_PATH = DATA_PATH / \"results\" / \"sim-30km\" / SIM_NAME\n",
    " # First infection in The Netherlands minus incubation time:\n",
    "START_DATE = date(2020, 2, 27) - timedelta(days=5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and prepping data\n",
    "Okay, we have some data munging work to do first. Feel free to skip this and scroll down for the mapping goodies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load population & geo data\n",
    "This is the same data as used in [the previous post](https://jvlanalytics.nl/covid-19-simulation), taken from Statistics Netherlands. I'm using `GeoPandas` to load it. The `wkt` format is a way to define polygons as a string that Kepler.gl understands. These polygons are of neighbourhoods in The Netherlands: subdivision of municipalities. We also have the population numbers, which will be useful for normalizing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hood</th>\n",
       "      <th>muni</th>\n",
       "      <th>pop</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>geo_wkt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hood_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wijk 02 Belgisch Park</td>\n",
       "      <td>'s-Gravenhage</td>\n",
       "      <td>7955</td>\n",
       "      <td>4.292010</td>\n",
       "      <td>52.112078</td>\n",
       "      <td>POLYGON ((4.2874663832711484 52.11844854220218...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wijk 03 Westbroekpark en Duttendel</td>\n",
       "      <td>'s-Gravenhage</td>\n",
       "      <td>1855</td>\n",
       "      <td>4.303211</td>\n",
       "      <td>52.104034</td>\n",
       "      <td>POLYGON ((4.3000017436689992 52.09899194050742...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wijk 04 Benoordenhout</td>\n",
       "      <td>'s-Gravenhage</td>\n",
       "      <td>13320</td>\n",
       "      <td>4.321339</td>\n",
       "      <td>52.097413</td>\n",
       "      <td>POLYGON ((4.3273890785303832 52.09565737879255...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       hood           muni    pop       lon  \\\n",
       "hood_id                                                                       \n",
       "0                     Wijk 02 Belgisch Park  's-Gravenhage   7955  4.292010   \n",
       "1        Wijk 03 Westbroekpark en Duttendel  's-Gravenhage   1855  4.303211   \n",
       "2                     Wijk 04 Benoordenhout  's-Gravenhage  13320  4.321339   \n",
       "\n",
       "               lat                                            geo_wkt  \n",
       "hood_id                                                                \n",
       "0        52.112078  POLYGON ((4.2874663832711484 52.11844854220218...  \n",
       "1        52.104034  POLYGON ((4.3000017436689992 52.09899194050742...  \n",
       "2        52.097413  POLYGON ((4.3273890785303832 52.09565737879255...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pop = (gpd\n",
    "          .read_file(DATA_PATH / \"transformed\" / \"population.shp\")\n",
    "          .assign(centroid=lambda df: df[\"geometry\"].map(lambda geo: geo.centroid))\n",
    "          .assign(lon=lambda df: df.centroid.map(lambda c: c.x),\n",
    "                  lat=lambda df: df.centroid.map(lambda c: c.y),\n",
    "                  geo_wkt=lambda df: df[\"geometry\"].map(lambda geo: geo.to_wkt())\n",
    "          )\n",
    "          # \"hood\" is a engineering abbrevation here, rather than slang ;-)\n",
    "          [[\"hood\", \"muni\", \"pop\", \"lon\", \"lat\", \"geo_wkt\"]]\n",
    ")\n",
    "df_pop.index.name = \"hood_id\"\n",
    "df_pop.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load simulation data\n",
    "We have simulated counts of susceptible, infected, recovered and deceased persons, per neighbourhood, per day. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_rename_map = {\n",
    "    \"PersonState.untouched\": \"susceptible\",  # To be more in line with SIR models.\n",
    "    \"PersonState.infected\": \"infected\",\n",
    "    \"PersonState.recovered\": \"recovered\",\n",
    "    \"PersonState.deceased\": \"deceased\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_count_dfs = []\n",
    "\n",
    "for day, path_daily_count_csv in enumerate(sorted(SIM_RES_PATH.glob(\"daily_counts*\"))):\n",
    "    date = START_DATE + timedelta(days=day)\n",
    "\n",
    "    df_dc = (\n",
    "        pd.read_csv(path_daily_count_csv)\n",
    "        .assign(date=date)\n",
    "        .set_index([\"date\", \"hood_id\"])\n",
    "        .rename(columns=column_rename_map)\n",
    "        .applymap(int)\n",
    "    )\n",
    "    \n",
    "    daily_count_dfs.append(df_dc)\n",
    "    \n",
    "df_daily_counts = (\n",
    "    pd.concat(daily_count_dfs)\n",
    "    .sort_index()\n",
    "    # For display purposes:\n",
    "    .assign(date_str=lambda df: df.index.get_level_values(\"date\").strftime(\"%Y-%m-%d\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>susceptible</th>\n",
       "      <th>infected</th>\n",
       "      <th>recovered</th>\n",
       "      <th>deceased</th>\n",
       "      <th>date_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>hood_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2020-02-22</th>\n",
       "      <th>85</th>\n",
       "      <td>12030</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>9200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2020-10-28</th>\n",
       "      <th>2740</th>\n",
       "      <td>1654</td>\n",
       "      <td>44</td>\n",
       "      <td>3770</td>\n",
       "      <td>97</td>\n",
       "      <td>2020-10-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2741</th>\n",
       "      <td>740</td>\n",
       "      <td>6</td>\n",
       "      <td>1754</td>\n",
       "      <td>45</td>\n",
       "      <td>2020-10-28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    susceptible  infected  recovered  deceased    date_str\n",
       "date       hood_id                                                        \n",
       "2020-02-22 85             12030         0          0         0  2020-02-22\n",
       "           86              9200         0          0         0  2020-02-22\n",
       "2020-10-28 2740            1654        44       3770        97  2020-10-28\n",
       "           2741             740         6       1754        45  2020-10-28"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat((df_daily_counts.head(2), df_daily_counts.tail(2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join the two datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I haven't found a way to join two datasets in Kepler.gl. Which is a shame when using time series data with static polygons, because these relatively large polygons have to duplicated for every timestep. This - as we shall see below - blows up the dataset to such an extent that Kepler refuses to work with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>susceptible</th>\n",
       "      <th>infected</th>\n",
       "      <th>recovered</th>\n",
       "      <th>deceased</th>\n",
       "      <th>date_str</th>\n",
       "      <th>hood</th>\n",
       "      <th>muni</th>\n",
       "      <th>pop</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>geo_wkt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>hood_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2020-02-22</th>\n",
       "      <th>85</th>\n",
       "      <td>12030</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-22</td>\n",
       "      <td>Wijk 00 Aalsmeer</td>\n",
       "      <td>Aalsmeer</td>\n",
       "      <td>12030</td>\n",
       "      <td>4.736807</td>\n",
       "      <td>52.253185</td>\n",
       "      <td>POLYGON ((4.7437654333167867 52.26983760839533...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>9200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-22</td>\n",
       "      <td>Wijk 01 Kudelstraat en Kalslagen</td>\n",
       "      <td>Aalsmeer</td>\n",
       "      <td>9200</td>\n",
       "      <td>4.739852</td>\n",
       "      <td>52.237020</td>\n",
       "      <td>POLYGON ((4.7550087572913968 52.25162737834186...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>9840</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-22</td>\n",
       "      <td>Wijk 02 Oosteinde</td>\n",
       "      <td>Aalsmeer</td>\n",
       "      <td>9840</td>\n",
       "      <td>4.795393</td>\n",
       "      <td>52.282207</td>\n",
       "      <td>POLYGON ((4.7680638414593837 52.27023804377086...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    susceptible  infected  recovered  deceased    date_str  \\\n",
       "date       hood_id                                                           \n",
       "2020-02-22 85             12030         0          0         0  2020-02-22   \n",
       "           86              9200         0          0         0  2020-02-22   \n",
       "           87              9840         0          0         0  2020-02-22   \n",
       "\n",
       "                                                hood      muni    pop  \\\n",
       "date       hood_id                                                      \n",
       "2020-02-22 85                       Wijk 00 Aalsmeer  Aalsmeer  12030   \n",
       "           86       Wijk 01 Kudelstraat en Kalslagen  Aalsmeer   9200   \n",
       "           87                      Wijk 02 Oosteinde  Aalsmeer   9840   \n",
       "\n",
       "                         lon        lat  \\\n",
       "date       hood_id                        \n",
       "2020-02-22 85       4.736807  52.253185   \n",
       "           86       4.739852  52.237020   \n",
       "           87       4.795393  52.282207   \n",
       "\n",
       "                                                              geo_wkt  \n",
       "date       hood_id                                                     \n",
       "2020-02-22 85       POLYGON ((4.7437654333167867 52.26983760839533...  \n",
       "           86       POLYGON ((4.7550087572913968 52.25162737834186...  \n",
       "           87       POLYGON ((4.7680638414593837 52.27023804377086...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_daily_counts_geo = df_daily_counts.merge(df_pop, left_index=True, right_index=True, how=\"inner\")\n",
    "df_daily_counts_geo.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create normalized counts\n",
    "It's all too easy to create maps that simply reflect the population density. A good way to compensate for that is to normalize: divide by the total population count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily_counts_geo[\"infected_percentage\"] = \\\n",
    "    (df_daily_counts_geo[\"infected\"] / df_daily_counts_geo[\"pop\"] * 100).round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to do a bit of hacking in order to make Kepler normalize across the entire time series. There is no built-in feature that does this. I'm using a small dummy triangle in the North Sea, outside of the visible area, with the relevant maximums:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummy = pd.DataFrame(data={\n",
    "    \"date\": df_daily_counts_geo.index.get_level_values(\"date\").unique(),\n",
    "    \"date_str\": df_daily_counts_geo.index.get_level_values(\"date\").unique().strftime(\"%Y-%m-%d\"),\n",
    "    \"hood_id\": -1,\n",
    "    \"hood\": \"dummy\",\n",
    "    \"muni\": \"dummy\",\n",
    "    \"pop\": 0,\n",
    "    \"infected\": df_daily_counts_geo[\"infected\"].max(),\n",
    "    \"infected_percentage\": df_daily_counts_geo[\"infected_percentage\"].max(),\n",
    "    \"lon\": 3.3267975,\n",
    "    \"lat\": 52.3911063,\n",
    "    \"geo_wkt\": \"POLYGON ((3.3267975 52.3911063, 3.3535767 52.3638604, 3.3851624 52.3915253))\",\n",
    "}).set_index([\"date\", \"hood_id\"])\n",
    "\n",
    "df = pd.concat((df_daily_counts_geo, df_dummy)).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>susceptible</th>\n",
       "      <th>infected</th>\n",
       "      <th>recovered</th>\n",
       "      <th>deceased</th>\n",
       "      <th>date_str</th>\n",
       "      <th>hood</th>\n",
       "      <th>muni</th>\n",
       "      <th>pop</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>geo_wkt</th>\n",
       "      <th>infected_percentage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>hood_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-22</th>\n",
       "      <th>-1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>24339</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-02-22</td>\n",
       "      <td>dummy</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0</td>\n",
       "      <td>3.326798</td>\n",
       "      <td>52.391106</td>\n",
       "      <td>POLYGON ((3.3267975 52.3911063, 3.3535767 52.3...</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-23</th>\n",
       "      <th>-1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>24339</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-02-23</td>\n",
       "      <td>dummy</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0</td>\n",
       "      <td>3.326798</td>\n",
       "      <td>52.391106</td>\n",
       "      <td>POLYGON ((3.3267975 52.3911063, 3.3535767 52.3...</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    susceptible  infected  recovered  deceased    date_str  \\\n",
       "date       hood_id                                                           \n",
       "2020-02-22 -1               NaN     24339        NaN       NaN  2020-02-22   \n",
       "2020-02-23 -1               NaN     24339        NaN       NaN  2020-02-23   \n",
       "\n",
       "                     hood   muni  pop       lon        lat  \\\n",
       "date       hood_id                                           \n",
       "2020-02-22 -1       dummy  dummy    0  3.326798  52.391106   \n",
       "2020-02-23 -1       dummy  dummy    0  3.326798  52.391106   \n",
       "\n",
       "                                                              geo_wkt  \\\n",
       "date       hood_id                                                      \n",
       "2020-02-22 -1       POLYGON ((3.3267975 52.3911063, 3.3535767 52.3...   \n",
       "2020-02-23 -1       POLYGON ((3.3267975 52.3911063, 3.3535767 52.3...   \n",
       "\n",
       "                    infected_percentage  \n",
       "date       hood_id                       \n",
       "2020-02-22 -1                      24.0  \n",
       "2020-02-23 -1                      24.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[(slice(None), -1), :].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping with Kepler.gl\n",
    "Let's fire up Kepler. The config can be stored in a JSON file and passed into the `KeplerGl(..)` constructor as seen below. Modifications are best made in the GUI, after which the JSON can be stored in order to re-create the map later.  It has pretty sensible default behavior by automatically parsing the `lon`/`lat`/`geo_wkt` columns, but some tweaking is usually required still."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map 1: Circles like the famous John Hopkins Covid-19 map\n",
    "I'll first attempt to re-create the [John Hopkins Covid-19 map](https://gisanddata.maps.arcgis.com/apps/opsdashboard/index.htmlfbclid=IwAR0Q7KKPfPT3uhysJlRi8fTpqNzHkMkd6NOWDYA7tkDYuSFCuHs85Z2e-uw#/bda7594740fd40299423467b48e9ecf6), which shows cumulative counts of reported infections. The underlying data is updated on a daily basis. It's not very detailed for The Netherlands, unfortunately:\n",
    "\n",
    "![John Hopkins map Europe](assets/img/john_hopkins.png \"John Hopkins map Europe\")\n",
    "\n",
    "This version will be zoomed in to a 30km radius around Schiphol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2fd070fa2d24a899b4bf7e10007442c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "KeplerGl(config={'version': 'v1', 'config': {'visState': {'filters': [{'dataId': 'data', 'id': 'x8ikqz08r', 'n…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Guide: https://github.com/keplergl/kepler.gl/blob/master/docs/keplergl-jupyter/user-guide.md\n"
     ]
    }
   ],
   "source": [
    "KEPLER_CONF_CIRCLES = \"kepler-config-circles.json\"\n",
    "COLS_CIRCLES = [\"infected\", \"infected_percentage\", \"hood\", \"muni\", \"lon\", \"lat\"]\n",
    "\n",
    "with open(KEPLER_CONF_CIRCLES, \"r\") as fp:\n",
    "    config = json.load(fp)\n",
    "\n",
    "map_circles = KeplerGl(\n",
    "    height=800, \n",
    "    data={\"data\": df[COLS_CIRCLES].reset_index()},\n",
    "    config=config\n",
    ")\n",
    "map_circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to run this after making changes in the GUI (if they need to be persisted):\n",
    "with open(KEPLER_CONF_CIRCLES, \"w\") as fp:\n",
    "    json.dump(map_circles.config, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Screenshot:\n",
    "\n",
    "![Circles map](assets/img/map_circles.png \"Circles map\")    \n",
    "\n",
    "The timeline feature is activated here. While it looks good, I am already facing some significant usability issues:\n",
    "\n",
    "- Kepler.gl does not work very well with data that's already aggregated per coordinate and per time interval. If, for example, the time range is 2 days, 2 circles will be drawn   on top of each other.\n",
    "- Hence, I want the time range to be exactly 1 day. This isn't doable in the GUI, but we can edit the JSON file manually (see `timeRange`, fill in Unix timestamps such that the   initial time is from 00:00:00 to 23:59:59 on the same day).\n",
    "- But now, with the time range indicator being exactly 1 day, it becomes too small to select. It's not possible anymore to navigate through the timeline by hand. I'm stuck with   using the play & pause buttons.\n",
    "- The bottom graph doesn't show anything useful, even when setting the y-axis.\n",
    "\n",
    "Kepler.gl seems to have been built for unaggregated data that is generated at a random moment in time. Which isn't a complete surprise, since this exactly describes the nature of Uber rides!\n",
    "\n",
    "Ideally, I'd use daily *new* cases rather than cumulative. If only we could inform Kepler to aggregate (sum) circles on the exact same coordinates instead of drawing them on top  of each other, this would be a fantastic way to easily identify areas with a lot of growth in a particular point in time. We wouldn't be stuck with a 1 day time range in that     case.\n",
    "\n",
    "But, I have to admit, the playback feature is very nice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video controls loop><source src=\"assets/vid/vid_circles_v3.mp4\"></video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('<video controls loop><source src=\"assets/vid/vid_circles_v3.mp4\"></video>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map 2: Choropleth map\n",
    "Choropleth maps are a common sight, but they can be tricky to interpret. For instance, they overemphasize the importance of large, potentially sparsely inhabited areas. Also, they hide differences within the regions and they may give the false impression of abrupt change at borders. \n",
    "\n",
    "But, it just so happens that my population data is on the level of neighbourhoods, and taking the centroid and placing a circle there doesn't do it justice entirely either. Let's see what it looks like with neighbourhood polygons. This time, I'll use the normalized infection numbers which allows us to identify areas that are more heavily affected, relatively speaking.\n",
    "\n",
    "Unfortunately, it seems impossible to load *all* data. As mentioned earlier, Kepler.gl requires data to be passed in a denormalized form. The Polygons are huge, and with the constraint of having to include them for every timestep, it seems I'm hitting some dataset size limit. It results in a Python stacktrace (`tornado.iostream.StreamClosedError`) and a JavaScript error in the browser console. This might just work when using Kepler.gl directly rather than through Python, but personally I'm much more interested in the Python API than the JavaScript API. Fortunately, if we limit the dataset to just 2 points per month, it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range = pd.date_range(start=df.date_str.min(), \n",
    "                           end=df.date_str.max(), freq=\"15D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Guide: https://github.com/keplergl/kepler.gl/blob/master/docs/keplergl-jupyter/user-guide.md\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d310c5f4efd5487caebc2e9a72b95601",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "KeplerGl(config={'version': 'v1', 'config': {'visState': {'filters': [{'dataId': 'data', 'id': 'y5phjeri9', 'n…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "KEPLER_CONF_CHORO_DYNAMIC = \"kepler-config-choro-dynamic.json\"\n",
    "COLS_CHORO = [\"infected_percentage\", \"hood\", \"muni\", \"geo_wkt\", \"date_str\"]\n",
    "\n",
    "with open(KEPLER_CONF_CHORO_DYNAMIC, \"r\") as fp:\n",
    "    config = json.load(fp)\n",
    "\n",
    "map_choro_dynamic = KeplerGl(\n",
    "    height=800, \n",
    "    data={\"data\": df[COLS_CHORO].loc[date_range, :].reset_index()},\n",
    "    config=config\n",
    ")\n",
    "\n",
    "map_choro_dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(KEPLER_CONF_CHORO_DYNAMIC, \"w\") as fp:\n",
    "    json.dump(map_choro_dynamic.config, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Screenshot:\n",
    "\n",
    "![Choropleth map](assets/img/map_choro_dynamic.png \"Choropleth map\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video controls loop><source src=\"assets/vid/vid_choro_v2.mp4\"></video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('<video controls loop><source src=\"assets/vid/vid_choro_v2.mp4\"></video>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, the key to getting the transitions *just right* is to edit the JSON file manually and change the unix timestamps in the `timeRange` field to be exactly equal to the    interval of the data. The GUI doesn't allow for sufficiently precise control. If the `timeRange` is slightly too small, the data disappears shortly. If the window is slightly too large, the two days in the window will be drawn on top of each other (which visually comes across as \"flickering\" due to the transparency).\n",
    "\n",
    "Now, there _is_ actually a hacky way to get daily data, but that involves taking the time control out of Kepler.gl and into the Python kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Guide: https://github.com/keplergl/kepler.gl/blob/master/docs/keplergl-jupyter/user-guide.md\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5729712013b249538091d1d316267b5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "KeplerGl(config={'version': 'v1', 'config': {'visState': {'filters': [], 'layers': [{'id': 'y08tsf', 'type': '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "KEPLER_CONF_CHORO_STATIC = \"kepler-config-choro-static.json\"\n",
    "COLS_CHORO = [\"infected_percentage\", \"hood\", \"muni\", \"geo_wkt\", \"date_str\"]\n",
    "\n",
    "with open(KEPLER_CONF_CHORO_STATIC, \"r\") as fp:\n",
    "    config = json.load(fp)\n",
    "\n",
    "map_choro_static = KeplerGl(\n",
    "    height=800, \n",
    "    data={\"data\": df[COLS_CHORO].loc[date_range.min()].reset_index()},\n",
    "    config=config\n",
    ")\n",
    "\n",
    "map_choro_static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(KEPLER_CONF_CHORO_STATIC, \"w\") as fp:\n",
    "    json.dump(map_choro_static.config, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for date in df.index.get_level_values(\"date\").unique():\n",
    "    new_data = df[COLS_CHORO].loc[date].reset_index()\n",
    "    map_choro_static.add_data(new_data, name=\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'd need to tune a `time.sleep(...)` call to slow it down if needed. I'm not doing it here: I'm happy with the speed I'm getting on my computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video controls loop><source src=\"assets/vid/vid_choro_workaround_v2.mp4\"></video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('<video controls loop><source src=\"assets/vid/vid_choro_workaround_v2.mp4\"></video>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to not having the timeline controls, we now have to use the tooltip to see the current. There's also no way to pause this easily or to go back and forward in time. Hence, this workaround is mostly useful for making videos (which, then, do allow pause and scrolling backwards and forwards, but obviously at the expense of other useful interactive things such as tooltips)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map 4: 3D histogram with hexbins\n",
    "Data Scientists love their histograms. The hexbin feature approximates a 3D histogram and looks pretty fancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Guide: https://github.com/keplergl/kepler.gl/blob/master/docs/keplergl-jupyter/user-guide.md\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dbf21178ea249c8a3fe38490925127d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "KeplerGl(config={'version': 'v1', 'config': {'visState': {'filters': [{'dataId': 'data', 'id': 'x8ikqz08r', 'n…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "KEPLER_CONF_HEXBIN = \"kepler-config-hexbin.json\"\n",
    "COLS_HEXBIN = [\"infected\", \"lon\", \"lat\"]\n",
    "\n",
    "with open(KEPLER_CONF_HEXBIN, \"r\") as fp:\n",
    "    config = json.load(fp)\n",
    "\n",
    "map_hexbin = KeplerGl(\n",
    "    height=800, \n",
    "    data={\"data\": df[COLS_HEXBIN].reset_index()},\n",
    "    config=config\n",
    ")\n",
    "map_hexbin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(KEPLER_CONF_HEXBIN, \"w\") as fp:\n",
    "    json.dump(map_hexbin.config, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Screenshot:\n",
    "\n",
    "![Hexbin map](assets/img/map_hexbin.png \"Hexbin map\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video controls loop><source src=\"assets/vid/vid_hexbin_v1.mp4\"></video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('<video controls loop><source src=\"assets/vid/vid_hexbin_v1.mp4\"></video>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a slight problem here with the color boundaries changing over time. This happens because my dummy triangle in the North Sea is no longer the max, due to summing multiple neighborhoods into a single hex bin. This is where my workaround to normalize across the entire time series breaks down.\n",
    "\n",
    "A fix isn't trivial, because the binning changes slightly as the map is moved around during playback.\n",
    "This is not great from a from a Data Science purism perspective, but it doesn't seem to have much impact here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kepler.gl looks fantastic and can be a great tool for exploring geographic time series interactively. It is especially well suited for datasets of unaggregated events at random   intervals. Special care must be taken when using pre-aggregated data on a fixed interval.\n",
    "\n",
    "The most important things on my wishlist are:\n",
    "- Ability to aggregate data (mean/sum) if it's on the exact same coordinate (at the very least for Points and Polygons).\n",
    "- Better support for fixed interval time series (e.g. daily). Getting the graph in the bottom to show something useful would be nice, but most importantly: having the ability to  move the selected time range around when it is relatively small would be very useful.\n",
    "- Built-in support for normalizing across the timeline.\n",
    "- A way to ship geo data separately and join it inside Kepler, in order to support large Polygon-based time series where the Polygons themselves remain static over time.\n",
    "- Consistent binning for the hexbin.\n",
    "\n",
    "I'll try to reach out to the team to see where they stand on this. For now, I'm happy to start using it in my projects! Thanks for reading!\n",
    "\n",
    "[Click here for the code](https://github.com/jvanlier/blog-notebooks/tree/master/evaluation-keplergl-covid-19-data)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
